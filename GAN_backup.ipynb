{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from data.data import load_mnist\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# p\n",
    "BATCH_SIZE = 512\n",
    "epochs = 200\n",
    "sample_size = 64 # fixed sample size\n",
    "nz = 128 # latent vector size\n",
    "k = 1 # number of steps to apply to the discriminator\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MNIST Dataset\n",
    "(xtrain, ytrain), (xval, yval), num_cls = load_mnist(final=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,)),\n",
    "])\n",
    "\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "train_data = datasets.MNIST(\n",
    "    root='input/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        self.nz = nz\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.nz, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_input = 784\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.n_input, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create real labels (1s)\n",
    "def label_real(size):\n",
    "    data = torch.ones(size, 1)\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create fake labels (0s)\n",
    "def label_fake(size):\n",
    "    data = torch.zeros(size, 1)\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to create the noise vector\n",
    "def create_noise(sample_size, nz):\n",
    "    return torch.randn(sample_size, nz).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the discriminator network\n",
    "def train_discriminator(optimizer, data_real, data_fake):\n",
    "    b_size = data_real.size(0)\n",
    "    real_label = label_real(b_size)\n",
    "    fake_label = label_fake(b_size)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output_real = discriminator(data_real)\n",
    "    loss_real = criterion(output_real, real_label)\n",
    "\n",
    "    output_fake = discriminator(data_fake)\n",
    "    loss_fake = criterion(output_fake, fake_label)\n",
    "\n",
    "\n",
    "    loss_real.backward()\n",
    "    loss_fake.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_real + loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the generator network\n",
    "def train_generator(optimizer, data_fake):\n",
    "    b_size = data_fake.size(0)\n",
    "    real_label = label_real(b_size)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = discriminator(data_fake)\n",
    "    loss = criterion(output, real_label)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(nz).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "print(generator)\n",
    "print(discriminator)\n",
    "\n",
    "\n",
    "# optimizers\n",
    "optim_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optim_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "losses_g = [] # to store generator loss after each epoch\n",
    "losses_d = [] # to store discriminator loss after each epoch\n",
    "images = [] # to store images generatd by the generator\n",
    "\n",
    "def train():\n",
    "    # create the noise vector\n",
    "    noise = create_noise(sample_size, nz)\n",
    "\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        loss_g = 0.0\n",
    "        loss_d = 0.0\n",
    "        for bi, data in tqdm(enumerate(train_loader), total=int(len(train_data)/train_loader.batch_size)):\n",
    "            image, _ = data\n",
    "            image = image.to(device)\n",
    "            b_size = len(image)\n",
    "            # run the discriminator for k number of steps\n",
    "            for step in range(k):\n",
    "                data_fake = generator(create_noise(b_size, nz)).detach()\n",
    "                data_real = image\n",
    "                # train the discriminator network\n",
    "                loss_d += train_discriminator(optim_d, data_real, data_fake)\n",
    "            data_fake = generator(create_noise(b_size, nz))\n",
    "            # train the generator network\n",
    "            loss_g += train_generator(optim_g, data_fake)\n",
    "\n",
    "        # create the final fake image for the epoch\n",
    "        generated_img = generator(noise).cpu().detach()\n",
    "        # make the images as grid\n",
    "        generated_img = make_grid(generated_img)\n",
    "        images.append(generated_img)\n",
    "        epoch_loss_g = loss_g / bi # loss generator \n",
    "        epoch_loss_d = loss_d / bi # loss discriminator\n",
    "        losses_g.append(epoch_loss_g)\n",
    "        losses_d.append(epoch_loss_d)\n",
    "\n",
    "        #SAVE IMAGE\n",
    "        imgs = [np.array(to_pil_image(img)) for img in images]\n",
    "        from PIL import Image\n",
    "        im = Image.fromarray(imgs[epoch])\n",
    "        im.save(\"Images_output/epoch_\"+str(epoch)+\".jpeg\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        print(f'Epoch: {epoch+1:02} of {epochs}| Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")\n",
    "        print(25*'==')\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [01:29,  1.32it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 of 1| Epoch Time: 1m 29s\n",
      "Generator loss: 1.18309736, Discriminator loss: 1.02536786\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "images = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [np.array(to_pil_image(img)) for img in images]\n",
    "\n",
    "imageio.mimsave('Images_output/generator_images.gif', imgs)\n",
    "from PIL import Image\n",
    "im = Image.fromarray(imgs[0])\n",
    "im.save(\"Images_output/epoch_0.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
