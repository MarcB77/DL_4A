{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "\n",
    "to_pil_image = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=T.Compose([T.Resize(32), T.ToTensor(), T.Lambda(lambda x: torch.flatten(x))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "svhn_train = datasets.SVHN(\n",
    "    root='data',\n",
    "    download=True,\n",
    "    transform=T.Compose([ T.ToTensor(), T.Lambda(lambda x: torch.flatten(x))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size = 300, latent_size = 100):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, 2 * latent_size)\n",
    "        )\n",
    "    \n",
    "    def sample(self, mu, sigma):\n",
    "        eps = torch.randn_like(sigma)\n",
    "        return mu + sigma * eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "\n",
    "        mu, log_var = torch.chunk(h, 2, dim=1)\n",
    "        sigma = torch.exp(0.5*log_var) \n",
    "        z = self.sample(mu, sigma)\n",
    "        \n",
    "        return z, mu, sigma\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size = 300, latent_size = 100):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(x) \n",
    "    \n",
    "class Prior(nn.Module):\n",
    "    def __init__(self, batch_size, latent_size=100):\n",
    "        super(Prior, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.p = torch.distributions.Normal(\n",
    "            torch.zeros((batch_size, self.latent_size)),\n",
    "            torch.ones((batch_size, self.latent_size))\n",
    "        )\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        z = torch.randn((batch_size, self.latent_size))\n",
    "        return z\n",
    "\n",
    "    def log_prob(self, z):\n",
    "\n",
    "        return self.p.log_prob(z)\n",
    "        \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_size)\n",
    "        self.decoder = Decoder(input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z, mu, sigma = self.encoder(x)\n",
    "                \n",
    "        return self.decoder(z), z, mu, sigma\n",
    "    \n",
    "    \n",
    "class ELBO():\n",
    "    def __init__(self, prior):\n",
    "        self.prior = prior\n",
    "        self.reconstruction_error = nn.BCELoss(reduction='none')\n",
    "    \n",
    "    def kullback_Leibler_divergence(self, z, mu, sigma):\n",
    "        q = torch.distributions.Normal(mu, sigma)\n",
    "\n",
    "        log_qz = q.log_prob(z)\n",
    "        log_pz = self.prior.log_prob(z)\n",
    "        \n",
    "        kl = (log_qz - log_pz).sum(-1)\n",
    "        \n",
    "        return kl\n",
    "    \n",
    "    def __call__(self, inputs, outputs, z, mu, sigma):\n",
    "        \n",
    "        re = self.reconstruction_error(outputs, inputs).sum(-1)\n",
    "        kl = self.kullback_Leibler_divergence(z, mu, sigma)\n",
    "\n",
    "        elbo = re + kl\n",
    "        return elbo.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(net, train_data, img_dim, batch_size=10, learning_rate=0.0001, epochs=20, nr_test_samples=64):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    prior = Prior(batch_size)\n",
    "    criterion = ELBO(prior)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    running_loss = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch:\" , epoch+1)\n",
    "\n",
    "        for i, data in tqdm(enumerate(train_loader), total=int(len(train_data)/train_loader.batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs, z, mu, sigma = net(inputs)\n",
    "            \n",
    "            # Backward\n",
    "            loss = criterion(inputs, outputs, z, mu, sigma)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss.append(loss.item())\n",
    "            \n",
    "        sample = prior.sample(nr_test_samples)\n",
    "        generated_img = net.decoder(sample).view(nr_test_samples,img_dim,32,32)\n",
    "        generated_img = make_grid(generated_img)\n",
    "    \n",
    "        #SAVE IMAGE\n",
    "        im = Image.fromarray(np.array(to_pil_image(generated_img)))\n",
    "        im.save(f\"Images_output/vae/epoch_{epoch}.jpeg\")\n",
    "\n",
    "        print(f'Loss: {np.mean(running_loss[-len(train_data):])}')\n",
    "    \n",
    "    return running_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/6000 [00:00<00:56, 105.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:52<00:00, 114.49it/s]\n",
      "  0%|          | 12/6000 [00:00<00:53, 112.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 250.30866422017417\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 168/6000 [00:01<00:50, 114.37it/s]"
     ]
    }
   ],
   "source": [
    "input_size = train_data[0][0].shape[0]\n",
    "\n",
    "net = VAE(input_size)\n",
    "\n",
    "loss = train(net, mnist_train, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
